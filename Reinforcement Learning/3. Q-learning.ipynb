{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Design and Neural Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen = 2000)\n",
    "        self.gamma = 0.95 #Discount Factor\n",
    "        #Exploration vs Exploitation Tradeoff\n",
    "        self.epsilon = 1.0 #100% Random Exploration\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.epsilon_min = 0.01\n",
    "        #Parameter for neural networks\n",
    "        self.learning_rate = 0.01\n",
    "        self.model = self._create_model()\n",
    "        \n",
    "    def _create_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim = self.state_size, activation = 'relu'))\n",
    "        model.add(Dense(24, activation = 'relu'))\n",
    "        model.add(Dense(self.action_size, activation = 'linear'))\n",
    "        model.compile(loss = 'mse', optimizer = Adam(lr = 0.001))\n",
    "        return model\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        #Remember past experience\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        \n",
    "    def act(self, state):\n",
    "        #Sampling according to the Epsilon Greedy method\n",
    "        if np.random.rand()<=self.epsilon:\n",
    "            #Take a random action\n",
    "            return random.randrange(self.action_size)\n",
    "        #Ask neural network to give me the most suitable action\n",
    "        return np.argmax(model.predict(state)[0])\n",
    "    \n",
    "    def train(self, batch_size=32):\n",
    "        #Training using a 'Replay Buffer'\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for experience in minibatch:\n",
    "            state,action,reward,next_state,done = experience\n",
    "        # X,Y : state, expected reward\n",
    "        if not done:\n",
    "            #if game is not yet over, then we use bellman equation to approximate the target value of reward\n",
    "            target = reward + self.gamma*np.amax(self.model.predict(next_state)[0])\n",
    "        else:\n",
    "            target = reward\n",
    "            \n",
    "        target_f = self.model.predict(state)\n",
    "        target_f[0][action] = target\n",
    "        \n",
    "        # X = state, Y = target_f\n",
    "        self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        \n",
    "        # as you're getting more experience, do not trust on randomness\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "            \n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 24)                120       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 50        \n",
      "=================================================================\n",
      "Total params: 770\n",
      "Trainable params: 770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim = 4, activation = 'relu'))\n",
    "model.add(Dense(24, activation = 'relu'))\n",
    "model.add(Dense(2, activation = 'linear'))\n",
    "model.compile(loss = 'mse', optimizer = Adam(lr = 0.001))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00202405, -0.04044954]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(1, 4) # 1 is the batch size here\n",
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the DQN Agent (Deep Q-Learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_episodes = 1000\n",
    "output_dir = \"cartpole_model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size=4, action_size=2)\n",
    "done = False\n",
    "state_size = 4\n",
    "action_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Episode :0/500 High Score :13 Exploration rate :1.0\n",
      "Game Episode :1/500 High Score :39 Exploration rate :1.0\n",
      "Game Episode :2/500 High Score :21 Exploration rate :0.99\n",
      "Game Episode :3/500 High Score :18 Exploration rate :0.99\n",
      "Game Episode :4/500 High Score :17 Exploration rate :0.99\n",
      "Game Episode :5/500 High Score :17 Exploration rate :0.98\n",
      "Game Episode :6/500 High Score :11 Exploration rate :0.98\n",
      "Game Episode :7/500 High Score :16 Exploration rate :0.97\n",
      "Game Episode :8/500 High Score :21 Exploration rate :0.97\n",
      "Game Episode :9/500 High Score :70 Exploration rate :0.96\n",
      "Game Episode :10/500 High Score :27 Exploration rate :0.96\n",
      "Game Episode :11/500 High Score :60 Exploration rate :0.95\n",
      "Game Episode :12/500 High Score :11 Exploration rate :0.95\n",
      "Game Episode :13/500 High Score :11 Exploration rate :0.94\n",
      "Game Episode :14/500 High Score :11 Exploration rate :0.94\n",
      "Game Episode :15/500 High Score :42 Exploration rate :0.93\n",
      "Game Episode :16/500 High Score :43 Exploration rate :0.93\n",
      "Game Episode :17/500 High Score :37 Exploration rate :0.92\n",
      "Game Episode :18/500 High Score :35 Exploration rate :0.92\n",
      "Game Episode :19/500 High Score :12 Exploration rate :0.91\n",
      "Game Episode :20/500 High Score :17 Exploration rate :0.91\n",
      "Game Episode :21/500 High Score :25 Exploration rate :0.9\n",
      "Game Episode :22/500 High Score :16 Exploration rate :0.9\n",
      "Game Episode :23/500 High Score :12 Exploration rate :0.9\n",
      "Game Episode :24/500 High Score :20 Exploration rate :0.89\n",
      "Game Episode :25/500 High Score :16 Exploration rate :0.89\n",
      "Game Episode :26/500 High Score :9 Exploration rate :0.88\n",
      "Game Episode :27/500 High Score :24 Exploration rate :0.88\n",
      "Game Episode :28/500 High Score :25 Exploration rate :0.87\n",
      "Game Episode :29/500 High Score :10 Exploration rate :0.87\n",
      "Game Episode :30/500 High Score :15 Exploration rate :0.86\n",
      "Game Episode :31/500 High Score :10 Exploration rate :0.86\n",
      "Game Episode :32/500 High Score :19 Exploration rate :0.86\n",
      "Game Episode :33/500 High Score :11 Exploration rate :0.85\n",
      "Game Episode :34/500 High Score :28 Exploration rate :0.85\n",
      "Game Episode :35/500 High Score :39 Exploration rate :0.84\n",
      "Game Episode :36/500 High Score :23 Exploration rate :0.84\n",
      "Game Episode :37/500 High Score :11 Exploration rate :0.83\n",
      "Game Episode :38/500 High Score :14 Exploration rate :0.83\n",
      "Game Episode :39/500 High Score :14 Exploration rate :0.83\n",
      "Game Episode :40/500 High Score :46 Exploration rate :0.82\n",
      "Game Episode :41/500 High Score :10 Exploration rate :0.82\n",
      "Game Episode :42/500 High Score :23 Exploration rate :0.81\n",
      "Game Episode :43/500 High Score :8 Exploration rate :0.81\n",
      "Game Episode :44/500 High Score :10 Exploration rate :0.81\n",
      "Game Episode :45/500 High Score :12 Exploration rate :0.8\n",
      "Game Episode :46/500 High Score :11 Exploration rate :0.8\n",
      "Game Episode :47/500 High Score :11 Exploration rate :0.79\n",
      "Game Episode :48/500 High Score :14 Exploration rate :0.79\n",
      "Game Episode :49/500 High Score :19 Exploration rate :0.79\n",
      "Game Episode :50/500 High Score :14 Exploration rate :0.78\n",
      "Game Episode :51/500 High Score :24 Exploration rate :0.78\n",
      "Game Episode :52/500 High Score :12 Exploration rate :0.77\n",
      "Game Episode :53/500 High Score :10 Exploration rate :0.77\n",
      "Game Episode :54/500 High Score :17 Exploration rate :0.77\n",
      "Game Episode :55/500 High Score :22 Exploration rate :0.76\n",
      "Game Episode :56/500 High Score :11 Exploration rate :0.76\n",
      "Game Episode :57/500 High Score :11 Exploration rate :0.76\n",
      "Game Episode :58/500 High Score :16 Exploration rate :0.75\n",
      "Game Episode :59/500 High Score :15 Exploration rate :0.75\n",
      "Game Episode :60/500 High Score :12 Exploration rate :0.74\n",
      "Game Episode :61/500 High Score :12 Exploration rate :0.74\n",
      "Game Episode :62/500 High Score :26 Exploration rate :0.74\n",
      "Game Episode :63/500 High Score :10 Exploration rate :0.73\n",
      "Game Episode :64/500 High Score :15 Exploration rate :0.73\n",
      "Game Episode :65/500 High Score :9 Exploration rate :0.73\n",
      "Game Episode :66/500 High Score :10 Exploration rate :0.72\n",
      "Game Episode :67/500 High Score :13 Exploration rate :0.72\n",
      "Game Episode :68/500 High Score :21 Exploration rate :0.71\n",
      "Game Episode :69/500 High Score :12 Exploration rate :0.71\n",
      "Game Episode :70/500 High Score :30 Exploration rate :0.71\n",
      "Game Episode :71/500 High Score :15 Exploration rate :0.7\n",
      "Game Episode :72/500 High Score :38 Exploration rate :0.7\n",
      "Game Episode :73/500 High Score :10 Exploration rate :0.7\n",
      "Game Episode :74/500 High Score :10 Exploration rate :0.69\n",
      "Game Episode :75/500 High Score :12 Exploration rate :0.69\n",
      "Game Episode :76/500 High Score :19 Exploration rate :0.69\n",
      "Game Episode :77/500 High Score :14 Exploration rate :0.68\n",
      "Game Episode :78/500 High Score :19 Exploration rate :0.68\n",
      "Game Episode :79/500 High Score :16 Exploration rate :0.68\n",
      "Game Episode :80/500 High Score :9 Exploration rate :0.67\n",
      "Game Episode :81/500 High Score :11 Exploration rate :0.67\n",
      "Game Episode :82/500 High Score :13 Exploration rate :0.67\n",
      "Game Episode :83/500 High Score :13 Exploration rate :0.66\n",
      "Game Episode :84/500 High Score :10 Exploration rate :0.66\n",
      "Game Episode :85/500 High Score :16 Exploration rate :0.66\n",
      "Game Episode :86/500 High Score :14 Exploration rate :0.65\n",
      "Game Episode :87/500 High Score :9 Exploration rate :0.65\n",
      "Game Episode :88/500 High Score :9 Exploration rate :0.65\n",
      "Game Episode :89/500 High Score :19 Exploration rate :0.64\n",
      "Game Episode :90/500 High Score :10 Exploration rate :0.64\n",
      "Game Episode :91/500 High Score :11 Exploration rate :0.64\n",
      "Game Episode :92/500 High Score :9 Exploration rate :0.63\n",
      "Game Episode :93/500 High Score :14 Exploration rate :0.63\n",
      "Game Episode :94/500 High Score :45 Exploration rate :0.63\n",
      "Game Episode :95/500 High Score :17 Exploration rate :0.62\n",
      "Game Episode :96/500 High Score :20 Exploration rate :0.62\n",
      "Game Episode :97/500 High Score :10 Exploration rate :0.62\n",
      "Game Episode :98/500 High Score :15 Exploration rate :0.61\n",
      "Game Episode :99/500 High Score :9 Exploration rate :0.61\n",
      "Game Episode :100/500 High Score :13 Exploration rate :0.61\n",
      "Game Episode :101/500 High Score :17 Exploration rate :0.61\n",
      "Game Episode :102/500 High Score :9 Exploration rate :0.6\n",
      "Game Episode :103/500 High Score :7 Exploration rate :0.6\n",
      "Game Episode :104/500 High Score :17 Exploration rate :0.6\n",
      "Game Episode :105/500 High Score :11 Exploration rate :0.59\n",
      "Game Episode :106/500 High Score :12 Exploration rate :0.59\n",
      "Game Episode :107/500 High Score :12 Exploration rate :0.59\n",
      "Game Episode :108/500 High Score :9 Exploration rate :0.58\n",
      "Game Episode :109/500 High Score :35 Exploration rate :0.58\n",
      "Game Episode :110/500 High Score :8 Exploration rate :0.58\n",
      "Game Episode :111/500 High Score :8 Exploration rate :0.58\n",
      "Game Episode :112/500 High Score :28 Exploration rate :0.57\n",
      "Game Episode :113/500 High Score :11 Exploration rate :0.57\n",
      "Game Episode :114/500 High Score :10 Exploration rate :0.57\n",
      "Game Episode :115/500 High Score :9 Exploration rate :0.56\n",
      "Game Episode :116/500 High Score :8 Exploration rate :0.56\n",
      "Game Episode :117/500 High Score :9 Exploration rate :0.56\n",
      "Game Episode :118/500 High Score :7 Exploration rate :0.56\n",
      "Game Episode :119/500 High Score :9 Exploration rate :0.55\n",
      "Game Episode :120/500 High Score :18 Exploration rate :0.55\n",
      "Game Episode :121/500 High Score :10 Exploration rate :0.55\n",
      "Game Episode :122/500 High Score :14 Exploration rate :0.55\n",
      "Game Episode :123/500 High Score :24 Exploration rate :0.54\n",
      "Game Episode :124/500 High Score :26 Exploration rate :0.54\n",
      "Game Episode :125/500 High Score :15 Exploration rate :0.54\n",
      "Game Episode :126/500 High Score :12 Exploration rate :0.53\n",
      "Game Episode :127/500 High Score :10 Exploration rate :0.53\n",
      "Game Episode :128/500 High Score :10 Exploration rate :0.53\n",
      "Game Episode :129/500 High Score :12 Exploration rate :0.53\n",
      "Game Episode :130/500 High Score :8 Exploration rate :0.52\n",
      "Game Episode :131/500 High Score :16 Exploration rate :0.52\n",
      "Game Episode :132/500 High Score :8 Exploration rate :0.52\n",
      "Game Episode :133/500 High Score :10 Exploration rate :0.52\n",
      "Game Episode :134/500 High Score :14 Exploration rate :0.51\n",
      "Game Episode :135/500 High Score :12 Exploration rate :0.51\n",
      "Game Episode :136/500 High Score :18 Exploration rate :0.51\n",
      "Game Episode :137/500 High Score :9 Exploration rate :0.51\n",
      "Game Episode :138/500 High Score :16 Exploration rate :0.5\n",
      "Game Episode :139/500 High Score :11 Exploration rate :0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Episode :140/500 High Score :12 Exploration rate :0.5\n",
      "Game Episode :141/500 High Score :8 Exploration rate :0.5\n",
      "Game Episode :142/500 High Score :18 Exploration rate :0.49\n",
      "Game Episode :143/500 High Score :9 Exploration rate :0.49\n",
      "Game Episode :144/500 High Score :12 Exploration rate :0.49\n",
      "Game Episode :145/500 High Score :8 Exploration rate :0.49\n",
      "Game Episode :146/500 High Score :12 Exploration rate :0.48\n",
      "Game Episode :147/500 High Score :11 Exploration rate :0.48\n",
      "Game Episode :148/500 High Score :39 Exploration rate :0.48\n",
      "Game Episode :149/500 High Score :12 Exploration rate :0.48\n",
      "Game Episode :150/500 High Score :13 Exploration rate :0.47\n",
      "Game Episode :151/500 High Score :13 Exploration rate :0.47\n",
      "Game Episode :152/500 High Score :9 Exploration rate :0.47\n",
      "Game Episode :153/500 High Score :10 Exploration rate :0.47\n",
      "Game Episode :154/500 High Score :9 Exploration rate :0.46\n",
      "Game Episode :155/500 High Score :8 Exploration rate :0.46\n",
      "Game Episode :156/500 High Score :15 Exploration rate :0.46\n",
      "Game Episode :157/500 High Score :17 Exploration rate :0.46\n",
      "Game Episode :158/500 High Score :11 Exploration rate :0.46\n",
      "Game Episode :159/500 High Score :8 Exploration rate :0.45\n",
      "Game Episode :160/500 High Score :7 Exploration rate :0.45\n",
      "Game Episode :161/500 High Score :9 Exploration rate :0.45\n",
      "Game Episode :162/500 High Score :12 Exploration rate :0.45\n",
      "Game Episode :163/500 High Score :15 Exploration rate :0.44\n",
      "Game Episode :164/500 High Score :11 Exploration rate :0.44\n",
      "Game Episode :165/500 High Score :15 Exploration rate :0.44\n",
      "Game Episode :166/500 High Score :8 Exploration rate :0.44\n",
      "Game Episode :167/500 High Score :16 Exploration rate :0.44\n",
      "Game Episode :168/500 High Score :10 Exploration rate :0.43\n",
      "Game Episode :169/500 High Score :11 Exploration rate :0.43\n",
      "Game Episode :170/500 High Score :17 Exploration rate :0.43\n",
      "Game Episode :171/500 High Score :7 Exploration rate :0.43\n",
      "Game Episode :172/500 High Score :8 Exploration rate :0.42\n",
      "Game Episode :173/500 High Score :21 Exploration rate :0.42\n",
      "Game Episode :174/500 High Score :10 Exploration rate :0.42\n",
      "Game Episode :175/500 High Score :12 Exploration rate :0.42\n",
      "Game Episode :176/500 High Score :10 Exploration rate :0.42\n",
      "Game Episode :177/500 High Score :8 Exploration rate :0.41\n",
      "Game Episode :178/500 High Score :13 Exploration rate :0.41\n",
      "Game Episode :179/500 High Score :9 Exploration rate :0.41\n",
      "Game Episode :180/500 High Score :10 Exploration rate :0.41\n",
      "Game Episode :181/500 High Score :7 Exploration rate :0.41\n",
      "Game Episode :182/500 High Score :11 Exploration rate :0.4\n",
      "Game Episode :183/500 High Score :11 Exploration rate :0.4\n",
      "Game Episode :184/500 High Score :10 Exploration rate :0.4\n",
      "Game Episode :185/500 High Score :8 Exploration rate :0.4\n",
      "Game Episode :186/500 High Score :11 Exploration rate :0.4\n",
      "Game Episode :187/500 High Score :11 Exploration rate :0.39\n",
      "Game Episode :188/500 High Score :10 Exploration rate :0.39\n",
      "Game Episode :189/500 High Score :7 Exploration rate :0.39\n",
      "Game Episode :190/500 High Score :12 Exploration rate :0.39\n",
      "Game Episode :191/500 High Score :10 Exploration rate :0.39\n",
      "Game Episode :192/500 High Score :10 Exploration rate :0.38\n",
      "Game Episode :193/500 High Score :14 Exploration rate :0.38\n",
      "Game Episode :194/500 High Score :12 Exploration rate :0.38\n",
      "Game Episode :195/500 High Score :9 Exploration rate :0.38\n",
      "Game Episode :196/500 High Score :9 Exploration rate :0.38\n",
      "Game Episode :197/500 High Score :13 Exploration rate :0.37\n",
      "Game Episode :198/500 High Score :9 Exploration rate :0.37\n",
      "Game Episode :199/500 High Score :9 Exploration rate :0.37\n",
      "Game Episode :200/500 High Score :10 Exploration rate :0.37\n",
      "Game Episode :201/500 High Score :8 Exploration rate :0.37\n",
      "Game Episode :202/500 High Score :8 Exploration rate :0.37\n",
      "Game Episode :203/500 High Score :8 Exploration rate :0.36\n",
      "Game Episode :204/500 High Score :12 Exploration rate :0.36\n",
      "Game Episode :205/500 High Score :11 Exploration rate :0.36\n",
      "Game Episode :206/500 High Score :7 Exploration rate :0.36\n",
      "Game Episode :207/500 High Score :13 Exploration rate :0.36\n",
      "Game Episode :208/500 High Score :11 Exploration rate :0.35\n",
      "Game Episode :209/500 High Score :10 Exploration rate :0.35\n",
      "Game Episode :210/500 High Score :7 Exploration rate :0.35\n",
      "Game Episode :211/500 High Score :9 Exploration rate :0.35\n",
      "Game Episode :212/500 High Score :12 Exploration rate :0.35\n",
      "Game Episode :213/500 High Score :8 Exploration rate :0.35\n",
      "Game Episode :214/500 High Score :10 Exploration rate :0.34\n",
      "Game Episode :215/500 High Score :12 Exploration rate :0.34\n",
      "Game Episode :216/500 High Score :8 Exploration rate :0.34\n",
      "Game Episode :217/500 High Score :8 Exploration rate :0.34\n",
      "Game Episode :218/500 High Score :9 Exploration rate :0.34\n",
      "Game Episode :219/500 High Score :10 Exploration rate :0.34\n",
      "Game Episode :220/500 High Score :15 Exploration rate :0.33\n",
      "Game Episode :221/500 High Score :12 Exploration rate :0.33\n",
      "Game Episode :222/500 High Score :8 Exploration rate :0.33\n",
      "Game Episode :223/500 High Score :13 Exploration rate :0.33\n",
      "Game Episode :224/500 High Score :10 Exploration rate :0.33\n",
      "Game Episode :225/500 High Score :9 Exploration rate :0.33\n",
      "Game Episode :226/500 High Score :13 Exploration rate :0.32\n",
      "Game Episode :227/500 High Score :12 Exploration rate :0.32\n",
      "Game Episode :228/500 High Score :9 Exploration rate :0.32\n",
      "Game Episode :229/500 High Score :10 Exploration rate :0.32\n",
      "Game Episode :230/500 High Score :9 Exploration rate :0.32\n",
      "Game Episode :231/500 High Score :8 Exploration rate :0.32\n",
      "Game Episode :232/500 High Score :15 Exploration rate :0.31\n",
      "Game Episode :233/500 High Score :9 Exploration rate :0.31\n",
      "Game Episode :234/500 High Score :10 Exploration rate :0.31\n",
      "Game Episode :235/500 High Score :9 Exploration rate :0.31\n",
      "Game Episode :236/500 High Score :10 Exploration rate :0.31\n",
      "Game Episode :237/500 High Score :14 Exploration rate :0.31\n",
      "Game Episode :238/500 High Score :8 Exploration rate :0.3\n",
      "Game Episode :239/500 High Score :17 Exploration rate :0.3\n",
      "Game Episode :240/500 High Score :16 Exploration rate :0.3\n",
      "Game Episode :241/500 High Score :13 Exploration rate :0.3\n",
      "Game Episode :242/500 High Score :8 Exploration rate :0.3\n",
      "Game Episode :243/500 High Score :11 Exploration rate :0.3\n",
      "Game Episode :244/500 High Score :9 Exploration rate :0.3\n",
      "Game Episode :245/500 High Score :11 Exploration rate :0.29\n",
      "Game Episode :246/500 High Score :10 Exploration rate :0.29\n",
      "Game Episode :247/500 High Score :8 Exploration rate :0.29\n",
      "Game Episode :248/500 High Score :9 Exploration rate :0.29\n",
      "Game Episode :249/500 High Score :11 Exploration rate :0.29\n",
      "Game Episode :250/500 High Score :9 Exploration rate :0.29\n",
      "Game Episode :251/500 High Score :11 Exploration rate :0.29\n",
      "Game Episode :252/500 High Score :10 Exploration rate :0.28\n",
      "Game Episode :253/500 High Score :9 Exploration rate :0.28\n",
      "Game Episode :254/500 High Score :11 Exploration rate :0.28\n",
      "Game Episode :255/500 High Score :8 Exploration rate :0.28\n",
      "Game Episode :256/500 High Score :10 Exploration rate :0.28\n",
      "Game Episode :257/500 High Score :8 Exploration rate :0.28\n",
      "Game Episode :258/500 High Score :8 Exploration rate :0.28\n",
      "Game Episode :259/500 High Score :8 Exploration rate :0.27\n",
      "Game Episode :260/500 High Score :7 Exploration rate :0.27\n",
      "Game Episode :261/500 High Score :8 Exploration rate :0.27\n",
      "Game Episode :262/500 High Score :8 Exploration rate :0.27\n",
      "Game Episode :263/500 High Score :9 Exploration rate :0.27\n",
      "Game Episode :264/500 High Score :10 Exploration rate :0.27\n",
      "Game Episode :265/500 High Score :8 Exploration rate :0.27\n",
      "Game Episode :266/500 High Score :7 Exploration rate :0.26\n",
      "Game Episode :267/500 High Score :8 Exploration rate :0.26\n",
      "Game Episode :268/500 High Score :11 Exploration rate :0.26\n",
      "Game Episode :269/500 High Score :9 Exploration rate :0.26\n",
      "Game Episode :270/500 High Score :14 Exploration rate :0.26\n",
      "Game Episode :271/500 High Score :8 Exploration rate :0.26\n",
      "Game Episode :272/500 High Score :10 Exploration rate :0.26\n",
      "Game Episode :273/500 High Score :9 Exploration rate :0.26\n",
      "Game Episode :274/500 High Score :8 Exploration rate :0.25\n",
      "Game Episode :275/500 High Score :10 Exploration rate :0.25\n",
      "Game Episode :276/500 High Score :8 Exploration rate :0.25\n",
      "Game Episode :277/500 High Score :11 Exploration rate :0.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Episode :278/500 High Score :10 Exploration rate :0.25\n",
      "Game Episode :279/500 High Score :8 Exploration rate :0.25\n",
      "Game Episode :280/500 High Score :7 Exploration rate :0.25\n",
      "Game Episode :281/500 High Score :13 Exploration rate :0.25\n",
      "Game Episode :282/500 High Score :15 Exploration rate :0.24\n",
      "Game Episode :283/500 High Score :8 Exploration rate :0.24\n",
      "Game Episode :284/500 High Score :9 Exploration rate :0.24\n",
      "Game Episode :285/500 High Score :10 Exploration rate :0.24\n",
      "Game Episode :286/500 High Score :7 Exploration rate :0.24\n",
      "Game Episode :287/500 High Score :8 Exploration rate :0.24\n",
      "Game Episode :288/500 High Score :8 Exploration rate :0.24\n",
      "Game Episode :289/500 High Score :11 Exploration rate :0.24\n",
      "Game Episode :290/500 High Score :12 Exploration rate :0.23\n",
      "Game Episode :291/500 High Score :10 Exploration rate :0.23\n",
      "Game Episode :292/500 High Score :9 Exploration rate :0.23\n",
      "Game Episode :293/500 High Score :7 Exploration rate :0.23\n",
      "Game Episode :294/500 High Score :8 Exploration rate :0.23\n",
      "Game Episode :295/500 High Score :11 Exploration rate :0.23\n",
      "Game Episode :296/500 High Score :8 Exploration rate :0.23\n",
      "Game Episode :297/500 High Score :7 Exploration rate :0.23\n",
      "Game Episode :298/500 High Score :14 Exploration rate :0.23\n",
      "Game Episode :299/500 High Score :8 Exploration rate :0.22\n",
      "Game Episode :300/500 High Score :14 Exploration rate :0.22\n",
      "Game Episode :301/500 High Score :8 Exploration rate :0.22\n",
      "Game Episode :302/500 High Score :11 Exploration rate :0.22\n",
      "Game Episode :303/500 High Score :8 Exploration rate :0.22\n"
     ]
    }
   ],
   "source": [
    "for e in range(n_episodes):\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, state_size]) # 1 is the batch size here\n",
    "    batch_size = 32\n",
    "    \n",
    "    for time in range(500):\n",
    "        env.render()\n",
    "        action = agent.act(state) # action is 0 or 1\n",
    "        next_state, reward, done, other_info = env.step(action)\n",
    "        reward = reward if not done else -10\n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        agent.remember(state, action, reward, next_state, done) #Experience for the agent\n",
    "        \n",
    "        if done:\n",
    "            print(\"Game Episode :{}/{} High Score :{} Exploration rate :{:.2}\".format(e, 500, time, agent.epsilon))\n",
    "            break\n",
    "            \n",
    "    if len(agent.memory) > batch_size:\n",
    "        agent.train(batch_size)\n",
    "    if e%50==0:\n",
    "        agent.save(output_dir+\"weights_\"+'{:04d}'.format(e)+\".hdf5\")\n",
    "        \n",
    "print(\"Deep Q-Learner Model Trainder\") \n",
    "#Although this is a shallow NN, \n",
    "#you can train a CNN or a more dense NN \n",
    "#depending upon the complexity of the game for which you're taining the network\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
